# =========================
# Project and runtime
# =========================
device: auto
seed: 99

project:
  data_dir: data
  raw_data_dir: data/raw
  processed_data_dir: data/processed
  metadata_csv: data/processed/metadata.csv
  features_dir: data/processed/features
  features_metadata_csv: data/processed/features/features_metadata.csv
  splits_dir: data/processed/splits
  train_csv: data/processed/splits/train.csv
  val_csv: data/processed/splits/val.csv
  test_csv: data/processed/splits/test.csv
  run_dir: runs

# =========================
# Datasets to extract
# =========================
extract:
  datasets: ["crema","ravdess","savee","tess"]

# =========================
# Emotion labels and maps
# =========================
emotion_labels:
  angry: 0
  disgust: 1
  fear: 2
  happy: 3
  neutral: 4
  sad: 5

emotion_maps:
  crema:
    ANG: angry
    DIS: disgust
    FEA: fear
    HAP: happy
    NEU: neutral
    SAD: sad
  ravdess:
    "01": neutral
    "02": neutral
    "03": happy
    "04": sad
    "05": angry
    "06": fear
    "07": disgust
    "08": surprise
  savee:
    a: angry
    d: disgust
    f: fear
    h: happy
    sa: sad
    su: surprise
  tess:
    angry: angry
    disgust: disgust
    fear: fear
    happy: happy
    neutral: neutral
    sad: sad
    surprise: surprise
    surprised: surprise
    ps: surprise

# =========================
# Split
# =========================
split:
  included_datasets: ["crema","ravdess","savee","tess"]
  cross_dataset: false
  train_datasets: ["crema","ravdess","savee"]  # used iff cross_dataset=true
  test_datasets: ["tess"]  # used iff cross_dataset=true
  group_by: speaker  # speaker | speaker+dataset | sample | none
  val_size: 0.10
  test_size: 0.15
  strict_required_features: true
  use_augmented_train: true
  use_augmented_val: false

# =========================
# Audio
# =========================
audio:
  sampling_rate: 16000
  duration: 3.0
  trim_silence:
    enabled: true
    top_db: 20

# =========================
# Feature extraction
# =========================
features:
  types: ["ssl", "mel", "mfcc", "chroma"]  # "ssl", "mel", "mfcc", "chroma"; features to compute/store
  augmented_types: ["mel", "mfcc", "chroma"]  # don't augment SSL
  normalize:
    mel: true
    mfcc: true
    chroma: false
  skip_existing: false

  stft:
    n_fft: 400
    hop_length: 160
    win_length: 400
    window: hann

  mel:
    n_mels: 128

  mfcc:
    n_mfcc: 40
    lifter: 0
    dct_type: 2

  ssl:
    backend: transformers
    model_id: microsoft/wavlm-base-plus

# =========================
# Audio augmentations (offline)
# =========================
augmentations:
  enabled: true
  copies: 1
  noise:        { enabled: true, prob: 0.3, factor: 0.002 }
  time_shift:   { enabled: true, prob: 0.3, max: 0.2 }
  pitch_shift:  { enabled: true, prob: 0.3, range: [-2, 2] }
  time_stretch: { enabled: true, prob: 0.3, range: [0.9, 1.1] }

# =========================
# SpecAugment (online, spectral only)
# =========================
specaugment:
  enabled: true
  freq_mask: { num: 2, param: 20 }
  time_mask: { num: 2, param: 30 }

# =========================
# Model
# =========================
model:
  name: ssl_spectral_moe
  features: ["ssl", "mel", "mfcc", "chroma"]

  moe:
    # SSL path
    ssl_proj_dim: 256
    ssl_encoder_layers: 1
    ssl_encoder_nhead: 4
    ssl_encoder_ff: 512
    ssl_encoder_dropout: 0.15

    # Spectral experts
    spec_hidden: 128
    spec_conv_layers: 2
    spec_kernel: 5
    spec_encoder_layers: 1  # 0 to ablate the tiny transformer
    spec_encoder_nhead: 4
    spec_encoder_ff: 512
    spec_encoder_dropout: 0.15

    # Pooling / fusion / classifier
    attn_hidden: 128
    fusion_dim: 256
    mlp_hidden: 256
    gate_hidden: 128
    gate_temperature: 0.85  # 0.7–1.0 (lower = sharper gate)
    gate_dropout: 0.15
    dropout: 0.5  # classifier MLP and pre-MLP dropout

    # Auxiliary head
    use_aux: false  # set true to enable aux classification on a spectral expert

# =========================
# Training
# =========================
train:
  epochs: 50
  batch_size: 32
  learning_rate: 1e-4
  weight_decay: 1e-4
  optimizer: adamw
  scheduler: cosine  # "cosine" | "none" | "plateau"

  val_metric: uar
  early_stopping_patience: 6

  amp: true
  grad_clip: 1.0
  num_workers: 2

  class_weighted_loss: false
  class_balancing: none  # "none" | "effective"
  loss: focal  # "ce" | "focal"
  focal_gamma: 1.0  # 1.0–2.0 common (higher focuses on hard samples)
  label_smoothing: 0.02
  use_weighted_sampler: false
